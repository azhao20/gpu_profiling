{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, sys\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '../..')))\n",
    "\n",
    "from utils.prediction_utils import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:20<00:00,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 249552 entries, 0 to 249551\n",
      "Data columns (total 8 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   n          249552 non-null  int64  \n",
      " 1   m          249552 non-null  int64  \n",
      " 2   p          249552 non-null  int64  \n",
      " 3   gflops     249552 non-null  float64\n",
      " 4   dtype_16   249552 non-null  bool   \n",
      " 5   dtype_32   249552 non-null  bool   \n",
      " 6   dtype_b16  249552 non-null  bool   \n",
      " 7   time       249552 non-null  float64\n",
      "dtypes: bool(3), float64(2), int64(3)\n",
      "memory usage: 10.2 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/Users/andrew/Desktop/Harvard/idreos-research/gpu_profiling\"\n",
    "X, y = get_data(\"mm\", base_dir, sample_rate=0.2)\n",
    "\n",
    "# Saving the result somewhere in case.\n",
    "df = pd.concat([X, y], axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss_function(predicted_alpha, target_operator_time, memory_accesses, intensity, pi, beta):\n",
    "    \"\"\"\n",
    "    predicted_alpha: Output from the neural network (predicted alpha)\n",
    "    target_operator_time: Actual operator times (ground truth)\n",
    "    memory_accesses: Precomputed memory accesses for each sample\n",
    "    intensity: Precomputed arithmetic intensity for each sample\n",
    "    pi: Precomputed dtype-specific peak FLOPs/sec (from dtype_to_peak_fp)\n",
    "    beta: DRAM bandwidth\n",
    "    \"\"\"\n",
    "    estimated_operator_time = torch.max(memory_accesses / pi, memory_accesses / (predicted_alpha * beta * intensity))\n",
    "    loss = nn.functional.mse_loss(estimated_operator_time, target_operator_time)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype({\"dtype_16\": int, \"dtype_32\": int, \"dtype_b16\": int})\n",
    "X = torch.tensor(X.values, dtype=torch.float32)\n",
    "y = torch.tensor(y)\n",
    "\n",
    "def get_dtype_bytes(row):\n",
    "    if row['dtype_32']:\n",
    "        return 4\n",
    "    elif row['dtype_16']:\n",
    "        return 2\n",
    "    elif row['dtype_b16']:\n",
    "        return 2\n",
    "    else:\n",
    "        raise ValueError(\"Unknown dtype in row.\")\n",
    "\n",
    "memory_accesses = (df[\"n\"] * df[\"m\"] + df[\"m\"] * df[\"p\"] + df[\"n\"] * df[\"p\"]) * df.apply(get_dtype_bytes, axis=1)\n",
    "intensity = (df[\"gflops\"] * 1e9) / memory_accesses\n",
    "\n",
    "memory_accesses = torch.tensor(memory_accesses.values, dtype=torch.float32)\n",
    "intensity = torch.tensor(intensity.values, dtype=torch.float32)\n",
    "\n",
    "def get_dtype_peak_fp(row):\n",
    "    # 156 for tf32.\n",
    "    if row['dtype_32']:\n",
    "        return 19.5\n",
    "    elif row['dtype_16']:\n",
    "        return 312\n",
    "    elif row['dtype_b16']:\n",
    "        return 312\n",
    "    else:\n",
    "        raise ValueError(\"Unknown dtype in row.\")\n",
    "\n",
    "# Note: hard-coded for A100.\n",
    "beta = 2.03904\n",
    "\n",
    "pi = df.apply(get_dtype_peak_fp, axis=1)\n",
    "pi = torch.tensor(pi.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([249552, 7])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "input_size = 7  # n, m, p, gflops, dtype_16, dtype_32, dtype_b16\n",
    "hidden_size = 64\n",
    "output_size = 1  # Predicting alpha or operator time\n",
    "model = Net(input_size, hidden_size, output_size)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    # Forward pass: predict alpha\n",
    "    predicted_alpha = model(X)\n",
    "    \n",
    "    # Compute the custom loss based on the predicted alpha\n",
    "    loss = custom_loss_function(predicted_alpha, y, memory_accesses, intensity, pi, beta)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Print loss every 10 epochs\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
